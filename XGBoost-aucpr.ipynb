{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAST CANCER PREDICTION - XG BOOST MODEL USING AUCPR\n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "#### Also ensure the kernel is _python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data managing and display libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the Sagemaker Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::396358375665:role/service-role/AmazonSageMaker-ExecutionRole-20200814T112856\n",
      "sagemaker-eu-west-1-396358375665\n"
     ]
    }
   ],
   "source": [
    "# sagemaker session, role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (rows, cols):  (569, 13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id.1</th>\n",
       "      <th>diag_value</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.192838</td>\n",
       "      <td>-1.948583</td>\n",
       "      <td>1.123166</td>\n",
       "      <td>-3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>-1.411424</td>\n",
       "      <td>-2.159370</td>\n",
       "      <td>-0.398406</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.877402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.387802</td>\n",
       "      <td>3.768172</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>-1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>-0.028657</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.240989</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>-1.106994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.733896</td>\n",
       "      <td>1.075174</td>\n",
       "      <td>0.551748</td>\n",
       "      <td>-0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>-0.541452</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.024066</td>\n",
       "      <td>-0.454275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.122953</td>\n",
       "      <td>-10.275589</td>\n",
       "      <td>3.232790</td>\n",
       "      <td>-0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>-3.053421</td>\n",
       "      <td>-1.429910</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>1.405438</td>\n",
       "      <td>1.116976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.935302</td>\n",
       "      <td>1.948071</td>\n",
       "      <td>-1.389767</td>\n",
       "      <td>-2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>1.226494</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.263806</td>\n",
       "      <td>-0.377705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      id.1  diag_value       c_1        c_2       c_3       c_4  \\\n",
       "0    842302    842302           1 -9.192838  -1.948583  1.123166 -3.633731   \n",
       "1    842517    842517           1 -2.387802   3.768172  0.529293 -1.118264   \n",
       "2  84300903  84300903           1 -5.733896   1.075174  0.551748 -0.912083   \n",
       "3  84348301  84348301           1 -7.122953 -10.275589  3.232790 -0.152547   \n",
       "4  84358402  84358402           1 -3.935302   1.948071 -1.389767 -2.940639   \n",
       "\n",
       "        c_5       c_6       c_7       c_8       c_9      c_10  \n",
       "0 -1.195110 -1.411424 -2.159370 -0.398406  0.157118  0.877402  \n",
       "1  0.621775 -0.028657 -0.013358  0.240989  0.711905 -1.106994  \n",
       "2 -0.177086 -0.541452  0.668167  0.097373 -0.024066 -0.454275  \n",
       "3 -2.960879 -3.053421 -1.429910  1.059565  1.405438  1.116976  \n",
       "4  0.546748  1.226494  0.936212  0.636376  0.263806 -0.377705  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the pca csv file\n",
    "local_data = 'data/pca.csv'\n",
    "\n",
    "# print out some data\n",
    "pca_bc_df = pd.read_csv(local_data)\n",
    "print('Data shape (rows, cols): ', pca_bc_df.shape)\n",
    "print()\n",
    "pca_bc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diag_value</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.192838</td>\n",
       "      <td>-1.948583</td>\n",
       "      <td>1.123166</td>\n",
       "      <td>-3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>-1.411424</td>\n",
       "      <td>-2.159370</td>\n",
       "      <td>-0.398406</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.877402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.387802</td>\n",
       "      <td>3.768172</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>-1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>-0.028657</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.240989</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>-1.106994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.733896</td>\n",
       "      <td>1.075174</td>\n",
       "      <td>0.551748</td>\n",
       "      <td>-0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>-0.541452</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.024066</td>\n",
       "      <td>-0.454275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1</td>\n",
       "      <td>-7.122953</td>\n",
       "      <td>-10.275589</td>\n",
       "      <td>3.232790</td>\n",
       "      <td>-0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>-3.053421</td>\n",
       "      <td>-1.429910</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>1.405438</td>\n",
       "      <td>1.116976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.935302</td>\n",
       "      <td>1.948071</td>\n",
       "      <td>-1.389767</td>\n",
       "      <td>-2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>1.226494</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.263806</td>\n",
       "      <td>-0.377705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          diag_value       c_1        c_2       c_3       c_4       c_5  \\\n",
       "id                                                                        \n",
       "842302             1 -9.192838  -1.948583  1.123166 -3.633731 -1.195110   \n",
       "842517             1 -2.387802   3.768172  0.529293 -1.118264  0.621775   \n",
       "84300903           1 -5.733896   1.075174  0.551748 -0.912083 -0.177086   \n",
       "84348301           1 -7.122953 -10.275589  3.232790 -0.152547 -2.960879   \n",
       "84358402           1 -3.935302   1.948071 -1.389767 -2.940639  0.546748   \n",
       "\n",
       "               c_6       c_7       c_8       c_9      c_10  \n",
       "id                                                          \n",
       "842302   -1.411424 -2.159370 -0.398406  0.157118  0.877402  \n",
       "842517   -0.028657 -0.013358  0.240989  0.711905 -1.106994  \n",
       "84300903 -0.541452  0.668167  0.097373 -0.024066 -0.454275  \n",
       "84348301 -3.053421 -1.429910  1.059565  1.405438  1.116976  \n",
       "84358402  1.226494  0.936212  0.636376  0.263806 -0.377705  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tidy up the columns and index\n",
    "\n",
    "pca_bc_df = pca_bc_df.drop('id.1', axis = 1)\n",
    "pca_bc_df.index=pca_bc_df['id'] \n",
    "pca_bc_df = pca_bc_df.drop('id', axis = 1)\n",
    "pca_bc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into Train, Validate and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "def train_test_split(df, train_frac= 0.7, seed=1):\n",
    "    '''Shuffle the data and randomly split into train and test sets;\n",
    "       separate the class labels (the column in df) from the features.\n",
    "       :param df: Dataframe of all TNA measurements\n",
    "       :param train_frac: The decimal fraction of data that should be training data\n",
    "       :param seed: Random seed for shuffling and reproducibility, default = 1\n",
    "       :return: Two tuples (in order): (train_features, train_labels), (test_features, test_labels)\n",
    "       '''\n",
    "    # convert dataframe to a matrix in order to use numpy shuffle\n",
    "    trans_matrix = df.to_numpy()\n",
    "    \n",
    "    # shuffle and split the data\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(trans_matrix)\n",
    "    \n",
    "    # define the training cut off from the number of rows\n",
    "    nTrain = int(trans_matrix.shape[0] * train_frac)\n",
    "    nFeatures = trans_matrix.shape[1]-1\n",
    "    \n",
    "    # the features are all columns except the first one\n",
    "    train_features = trans_matrix[:nTrain, 1: ]\n",
    "    train_labels = trans_matrix[:nTrain, :1 ]\n",
    "    \n",
    "    test_features = trans_matrix[nTrain: , 1: ]\n",
    "    test_labels = trans_matrix[nTrain: , :1 ]\n",
    "    \n",
    "    return (train_features, train_labels[: , 0]), (test_features, test_labels[: ,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/test data\n",
    "(train_features, train_labels), (test_features, test_labels) = train_test_split(pca_bc_df, train_frac=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.988462</td>\n",
       "      <td>-2.316048</td>\n",
       "      <td>-1.236304</td>\n",
       "      <td>-1.769776</td>\n",
       "      <td>0.143996</td>\n",
       "      <td>-0.133596</td>\n",
       "      <td>-0.365437</td>\n",
       "      <td>-0.498596</td>\n",
       "      <td>0.712368</td>\n",
       "      <td>-0.005232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.700007</td>\n",
       "      <td>-2.352272</td>\n",
       "      <td>3.078089</td>\n",
       "      <td>0.066021</td>\n",
       "      <td>-1.056466</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>0.160620</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>-0.592331</td>\n",
       "      <td>0.105427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.420223</td>\n",
       "      <td>-1.393978</td>\n",
       "      <td>0.836987</td>\n",
       "      <td>-1.105445</td>\n",
       "      <td>-0.364401</td>\n",
       "      <td>-0.089466</td>\n",
       "      <td>0.263475</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.475970</td>\n",
       "      <td>0.078254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.364876</td>\n",
       "      <td>3.574461</td>\n",
       "      <td>2.223978</td>\n",
       "      <td>-0.223168</td>\n",
       "      <td>0.778531</td>\n",
       "      <td>-0.510230</td>\n",
       "      <td>0.562793</td>\n",
       "      <td>0.235439</td>\n",
       "      <td>0.325623</td>\n",
       "      <td>-0.124681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934091</td>\n",
       "      <td>2.105945</td>\n",
       "      <td>-1.432917</td>\n",
       "      <td>2.894262</td>\n",
       "      <td>-1.275416</td>\n",
       "      <td>-1.626692</td>\n",
       "      <td>0.547604</td>\n",
       "      <td>0.850074</td>\n",
       "      <td>-0.368685</td>\n",
       "      <td>-0.292194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         0         1         2         3         4         5         6  \\\n",
       "0  0.0 -1.988462 -2.316048 -1.236304 -1.769776  0.143996 -0.133596 -0.365437   \n",
       "1  1.0 -1.700007 -2.352272  3.078089  0.066021 -1.056466  0.282110  0.160620   \n",
       "2  0.0  1.420223 -1.393978  0.836987 -1.105445 -0.364401 -0.089466  0.263475   \n",
       "3  1.0 -0.364876  3.574461  2.223978 -0.223168  0.778531 -0.510230  0.562793   \n",
       "4  1.0  0.934091  2.105945 -1.432917  2.894262 -1.275416 -1.626692  0.547604   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.498596  0.712368 -0.005232  \n",
       "1  0.018960 -0.592331  0.105427  \n",
       "2  0.964706  0.475970  0.078254  \n",
       "3  0.235439  0.325623 -0.124681  \n",
       "4  0.850074 -0.368685 -0.292194  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a training dataframe in order to further spliot into train and validate\n",
    "\n",
    "train_df = pd.concat([pd.DataFrame(train_labels), pd.DataFrame(train_features)], axis = 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/validate data\n",
    "(train_features, train_labels), (val_features, val_labels) = train_test_split(train_df, train_frac=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Train, Validate and test data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "# We use pandas to save our train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, it is assumed\n",
    "# that the first entry in each row is the target variable.\n",
    "\n",
    "pd.concat([pd.DataFrame(val_labels), pd.DataFrame(val_features)], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([pd.DataFrame(train_labels), pd.DataFrame(train_features)], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)\n",
    "\n",
    "\n",
    "pd.concat([pd.DataFrame(test_labels), pd.DataFrame(test_features)], axis=1).to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload the data to S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the Sagemaker session\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# get the role\n",
    "role = get_execution_role()\n",
    "\n",
    "# describe the s3 location prefix\n",
    "prefix = 'xgb'\n",
    "\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# construct the image name for the training container.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost', '1.0-1')\n",
    "\n",
    "\n",
    "# Now that we know which container to use, we can construct the estimator object.\n",
    "xgb = sagemaker.estimator.Estimator(container,                                   # The name of the training container\n",
    "                                    role,                                        # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1,                      # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge',          # The type of instance ot use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                                                                 # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=session) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the hyper parameters for the XG Boost model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,                      # Maximum depth of a tree. Increasing this value makes the model more complex and likely to be overfit\n",
    "                        eta=0.2,                          # size shrinkage used in updates to prevent overfitting\n",
    "                        gamma=4,                          # Minimum loss reduction required to make a further partition on a leaf node \n",
    "                        min_child_weight=6,               # min instances for each node\n",
    "                        subsample=0.8,                    # Subsample ratio of the training instance, 1-Subsample acts like. dropout for overfitting\n",
    "                        objective='binary:logistic',      # logistic regression for binary classification, output probability\n",
    "                        early_stopping_rounds=50,         # Validation error needs to decrease at least every early_stopping_rounds to continue training.\n",
    "                        num_round=200,                    # The number of rounds to run the training.\n",
    "                        eval_metric='aucpr'               # Precision Recall curve\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-12 13:58:26 Starting - Starting the training job...\n",
      "2020-10-12 13:58:28 Starting - Launching requested ML instances......\n",
      "2020-10-12 13:59:28 Starting - Preparing the instances for training...\n",
      "2020-10-12 14:00:22 Downloading - Downloading input data...\n",
      "2020-10-12 14:00:43 Training - Downloading the training image...\n",
      "2020-10-12 14:01:26 Uploading - Uploading generated training model\n",
      "2020-10-12 14:01:26 Completed - Training job completed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value aucpr to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:01:16] 318x10 matrix with 3180 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:01:16] 80x10 matrix with 800 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 318 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 80 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-aucpr:0.93083#011validation-aucpr:0.91221\u001b[0m\n",
      "\u001b[34m[1]#011train-aucpr:0.96819#011validation-aucpr:0.95405\u001b[0m\n",
      "\u001b[34m[2]#011train-aucpr:0.96819#011validation-aucpr:0.95405\u001b[0m\n",
      "\u001b[34m[3]#011train-aucpr:0.97037#011validation-aucpr:0.95362\u001b[0m\n",
      "\u001b[34m[4]#011train-aucpr:0.97324#011validation-aucpr:0.95742\u001b[0m\n",
      "\u001b[34m[5]#011train-aucpr:0.97604#011validation-aucpr:0.95742\u001b[0m\n",
      "\u001b[34m[6]#011train-aucpr:0.97728#011validation-aucpr:0.96177\u001b[0m\n",
      "\u001b[34m[7]#011train-aucpr:0.97537#011validation-aucpr:0.95918\u001b[0m\n",
      "\u001b[34m[8]#011train-aucpr:0.97778#011validation-aucpr:0.96032\u001b[0m\n",
      "\u001b[34m[9]#011train-aucpr:0.97944#011validation-aucpr:0.96304\u001b[0m\n",
      "\u001b[34m[10]#011train-aucpr:0.98163#011validation-aucpr:0.96276\u001b[0m\n",
      "\u001b[34m[11]#011train-aucpr:0.98362#011validation-aucpr:0.96464\u001b[0m\n",
      "\u001b[34m[12]#011train-aucpr:0.98550#011validation-aucpr:0.96884\u001b[0m\n",
      "\u001b[34m[13]#011train-aucpr:0.98468#011validation-aucpr:0.96525\u001b[0m\n",
      "\u001b[34m[14]#011train-aucpr:0.98719#011validation-aucpr:0.96696\u001b[0m\n",
      "\u001b[34m[15]#011train-aucpr:0.98640#011validation-aucpr:0.96696\u001b[0m\n",
      "\u001b[34m[16]#011train-aucpr:0.98685#011validation-aucpr:0.96845\u001b[0m\n",
      "\u001b[34m[17]#011train-aucpr:0.98892#011validation-aucpr:0.97104\u001b[0m\n",
      "\u001b[34m[18]#011train-aucpr:0.98914#011validation-aucpr:0.97278\u001b[0m\n",
      "\u001b[34m[19]#011train-aucpr:0.98863#011validation-aucpr:0.97278\u001b[0m\n",
      "\u001b[34m[20]#011train-aucpr:0.98851#011validation-aucpr:0.97323\u001b[0m\n",
      "\u001b[34m[21]#011train-aucpr:0.98990#011validation-aucpr:0.97426\u001b[0m\n",
      "\u001b[34m[22]#011train-aucpr:0.99072#011validation-aucpr:0.97614\u001b[0m\n",
      "\u001b[34m[23]#011train-aucpr:0.99072#011validation-aucpr:0.97614\u001b[0m\n",
      "\u001b[34m[24]#011train-aucpr:0.99072#011validation-aucpr:0.97614\u001b[0m\n",
      "\u001b[34m[25]#011train-aucpr:0.99072#011validation-aucpr:0.97614\u001b[0m\n",
      "\u001b[34m[26]#011train-aucpr:0.99072#011validation-aucpr:0.97614\u001b[0m\n",
      "\u001b[34m[27]#011train-aucpr:0.99172#011validation-aucpr:0.97639\u001b[0m\n",
      "\u001b[34m[28]#011train-aucpr:0.99244#011validation-aucpr:0.97787\u001b[0m\n",
      "\u001b[34m[29]#011train-aucpr:0.99305#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[30]#011train-aucpr:0.99305#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[31]#011train-aucpr:0.99235#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[32]#011train-aucpr:0.99235#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[33]#011train-aucpr:0.99235#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[34]#011train-aucpr:0.99235#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[35]#011train-aucpr:0.99235#011validation-aucpr:0.97660\u001b[0m\n",
      "\u001b[34m[36]#011train-aucpr:0.99179#011validation-aucpr:0.97580\u001b[0m\n",
      "\u001b[34m[37]#011train-aucpr:0.99179#011validation-aucpr:0.97580\u001b[0m\n",
      "\u001b[34m[38]#011train-aucpr:0.99179#011validation-aucpr:0.97580\u001b[0m\n",
      "\u001b[34m[39]#011train-aucpr:0.99247#011validation-aucpr:0.97588\u001b[0m\n",
      "\u001b[34m[40]#011train-aucpr:0.99247#011validation-aucpr:0.97588\u001b[0m\n",
      "\u001b[34m[41]#011train-aucpr:0.99247#011validation-aucpr:0.97588\u001b[0m\n",
      "\u001b[34m[42]#011train-aucpr:0.99247#011validation-aucpr:0.97588\u001b[0m\n",
      "\u001b[34m[43]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[44]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[45]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[46]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[47]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[48]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[49]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[50]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[51]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[52]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[53]#011train-aucpr:0.99331#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[54]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[55]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[56]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[57]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[58]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[59]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[60]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[61]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[62]#011train-aucpr:0.99250#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[63]#011train-aucpr:0.99317#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[64]#011train-aucpr:0.99317#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[65]#011train-aucpr:0.99317#011validation-aucpr:0.97632\u001b[0m\n",
      "\u001b[34m[66]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[67]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[68]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[69]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[70]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[71]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[72]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[73]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[74]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[75]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[76]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[77]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "\u001b[34m[78]#011train-aucpr:0.99379#011validation-aucpr:0.97749\u001b[0m\n",
      "Training seconds: 64\n",
      "Billable seconds: 64\n"
     ]
    }
   ],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy the xg boost predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_df = pd.DataFrame(test_features)\n",
    "test_labels_df = pd.DataFrame(test_labels)\n",
    "\n",
    "train_features_df = pd.DataFrame(train_features)\n",
    "train_labels_df = pd.DataFrame(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chek the training dataset predictions as a robustness check with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "\n",
    "train_pred = xgb_predictor.predict(train_features_df.values).decode('utf-8')\n",
    "# predictions is currently a comma delimited string and so we would like to break it up\n",
    "# as a numpy array.\n",
    "train_pred = pd.DataFrame(np.fromstring(train_pred, sep=','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the test features in the predictor as the model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to tell the endpoint what format the data we are sending is in\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "\n",
    "test_pred = xgb_predictor.predict(test_features_df.values).decode('utf-8')\n",
    "# predictions is currently a comma delimited string and so we would like to break it up\n",
    "# as a numpy array.\n",
    "test_pred = pd.DataFrame(np.fromstring(test_pred, sep=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the scores to an outcome for evaluation\n",
    "train_pred.columns = ['Score']\n",
    "train_pred['Outcome'] = np.where(train_pred['Score']>=0.5,1.0,0.0)\n",
    "\n",
    "\n",
    "test_pred.columns = ['Score']\n",
    "test_pred['Outcome'] = np.where(test_pred['Score']>=0.5,1.0,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred['Outcome'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(test_preds, test_labels,  verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint outcomes.  \n",
    "    Return binary classification metrics.\n",
    "    :param test_preds: A prediction endpoint output as a dataframe\n",
    "    :param test_labels: Class labels for test data as a dataframe\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics XG Boost Model.\n",
      "\n",
      "prediction (col)  0.0  1.0\n",
      "actual (row)              \n",
      "0.0               200    4\n",
      "1.0                 7  107\n",
      "\n",
      "Recall:     0.939\n",
      "Precision:  0.964\n",
      "Accuracy:   0.965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Metrics XG Boost Model.\\n')\n",
    "\n",
    "# get metrics for xgb predictor\n",
    "metrics = evaluate(train_pred['Outcome'], \n",
    "                   train_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics XG Boost Model.\n",
      "\n",
      "prediction (col)  0.0  1.0\n",
      "actual (row)              \n",
      "0.0               107    1\n",
      "1.0                 5   58\n",
      "\n",
      "Recall:     0.921\n",
      "Precision:  0.983\n",
      "Accuracy:   0.965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics XG Boost Model.\\n')\n",
    "\n",
    "# get metrics for xgb predictor\n",
    "metrics = evaluate(test_pred['Outcome'], \n",
    "                   test_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes a precictor.endpoint\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-xgboost-2020-10-12-13-58-26-700\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(xgb_predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
