{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAST CANCER PREDICTION - NEURAL NETWORK MODEL\n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "#### Also ensure the kernel is _pytorch_p36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data managing and display libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the Sagemaker Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::396358375665:role/service-role/AmazonSageMaker-ExecutionRole-20200814T112856\n",
      "sagemaker-eu-west-1-396358375665\n"
     ]
    }
   ],
   "source": [
    "# sagemaker session, role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)\n",
    "\n",
    "# S3 bucket name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (rows, cols):  (569, 13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id.1</th>\n",
       "      <th>diag_value</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.192838</td>\n",
       "      <td>-1.948583</td>\n",
       "      <td>1.123166</td>\n",
       "      <td>-3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>-1.411424</td>\n",
       "      <td>-2.159370</td>\n",
       "      <td>-0.398406</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.877402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.387802</td>\n",
       "      <td>3.768172</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>-1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>-0.028657</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.240989</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>-1.106994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.733896</td>\n",
       "      <td>1.075174</td>\n",
       "      <td>0.551748</td>\n",
       "      <td>-0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>-0.541452</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.024066</td>\n",
       "      <td>-0.454275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.122953</td>\n",
       "      <td>-10.275589</td>\n",
       "      <td>3.232790</td>\n",
       "      <td>-0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>-3.053421</td>\n",
       "      <td>-1.429910</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>1.405438</td>\n",
       "      <td>1.116976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.935302</td>\n",
       "      <td>1.948071</td>\n",
       "      <td>-1.389767</td>\n",
       "      <td>-2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>1.226494</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.263806</td>\n",
       "      <td>-0.377705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      id.1  diag_value       c_1        c_2       c_3       c_4  \\\n",
       "0    842302    842302           1 -9.192838  -1.948583  1.123166 -3.633731   \n",
       "1    842517    842517           1 -2.387802   3.768172  0.529293 -1.118264   \n",
       "2  84300903  84300903           1 -5.733896   1.075174  0.551748 -0.912083   \n",
       "3  84348301  84348301           1 -7.122953 -10.275589  3.232790 -0.152547   \n",
       "4  84358402  84358402           1 -3.935302   1.948071 -1.389767 -2.940639   \n",
       "\n",
       "        c_5       c_6       c_7       c_8       c_9      c_10  \n",
       "0 -1.195110 -1.411424 -2.159370 -0.398406  0.157118  0.877402  \n",
       "1  0.621775 -0.028657 -0.013358  0.240989  0.711905 -1.106994  \n",
       "2 -0.177086 -0.541452  0.668167  0.097373 -0.024066 -0.454275  \n",
       "3 -2.960879 -3.053421 -1.429910  1.059565  1.405438  1.116976  \n",
       "4  0.546748  1.226494  0.936212  0.636376  0.263806 -0.377705  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the pca csv file\n",
    "local_data = 'data/pca.csv'\n",
    "\n",
    "# print out some data\n",
    "pca_bc_df = pd.read_csv(local_data)\n",
    "print('Data shape (rows, cols): ', pca_bc_df.shape)\n",
    "print()\n",
    "pca_bc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diag_value</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.192838</td>\n",
       "      <td>-1.948583</td>\n",
       "      <td>1.123166</td>\n",
       "      <td>-3.633731</td>\n",
       "      <td>-1.195110</td>\n",
       "      <td>-1.411424</td>\n",
       "      <td>-2.159370</td>\n",
       "      <td>-0.398406</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.877402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.387802</td>\n",
       "      <td>3.768172</td>\n",
       "      <td>0.529293</td>\n",
       "      <td>-1.118264</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>-0.028657</td>\n",
       "      <td>-0.013358</td>\n",
       "      <td>0.240989</td>\n",
       "      <td>0.711905</td>\n",
       "      <td>-1.106994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.733896</td>\n",
       "      <td>1.075174</td>\n",
       "      <td>0.551748</td>\n",
       "      <td>-0.912083</td>\n",
       "      <td>-0.177086</td>\n",
       "      <td>-0.541452</td>\n",
       "      <td>0.668167</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.024066</td>\n",
       "      <td>-0.454275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <td>1</td>\n",
       "      <td>-7.122953</td>\n",
       "      <td>-10.275589</td>\n",
       "      <td>3.232790</td>\n",
       "      <td>-0.152547</td>\n",
       "      <td>-2.960879</td>\n",
       "      <td>-3.053421</td>\n",
       "      <td>-1.429910</td>\n",
       "      <td>1.059565</td>\n",
       "      <td>1.405438</td>\n",
       "      <td>1.116976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.935302</td>\n",
       "      <td>1.948071</td>\n",
       "      <td>-1.389767</td>\n",
       "      <td>-2.940639</td>\n",
       "      <td>0.546748</td>\n",
       "      <td>1.226494</td>\n",
       "      <td>0.936212</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.263806</td>\n",
       "      <td>-0.377705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          diag_value       c_1        c_2       c_3       c_4       c_5  \\\n",
       "id                                                                        \n",
       "842302             1 -9.192838  -1.948583  1.123166 -3.633731 -1.195110   \n",
       "842517             1 -2.387802   3.768172  0.529293 -1.118264  0.621775   \n",
       "84300903           1 -5.733896   1.075174  0.551748 -0.912083 -0.177086   \n",
       "84348301           1 -7.122953 -10.275589  3.232790 -0.152547 -2.960879   \n",
       "84358402           1 -3.935302   1.948071 -1.389767 -2.940639  0.546748   \n",
       "\n",
       "               c_6       c_7       c_8       c_9      c_10  \n",
       "id                                                          \n",
       "842302   -1.411424 -2.159370 -0.398406  0.157118  0.877402  \n",
       "842517   -0.028657 -0.013358  0.240989  0.711905 -1.106994  \n",
       "84300903 -0.541452  0.668167  0.097373 -0.024066 -0.454275  \n",
       "84348301 -3.053421 -1.429910  1.059565  1.405438  1.116976  \n",
       "84358402  1.226494  0.936212  0.636376  0.263806 -0.377705  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tidy up the columns and index\n",
    "\n",
    "pca_bc_df = pca_bc_df.drop('id.1', axis = 1)\n",
    "pca_bc_df.index=pca_bc_df['id'] \n",
    "pca_bc_df = pca_bc_df.drop('id', axis = 1)\n",
    "pca_bc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/test\n",
    "def train_test_split(df, train_frac= 0.7, seed=1):\n",
    "    '''Shuffle the data and randomly split into train and test sets;\n",
    "       separate the class labels (the column in df) from the features.\n",
    "       :param df: Dataframe of all TNA measurements\n",
    "       :param train_frac: The decimal fraction of data that should be training data\n",
    "       :param seed: Random seed for shuffling and reproducibility, default = 1\n",
    "       :return: Two tuples (in order): (train_features, train_labels), (test_features, test_labels)\n",
    "       '''\n",
    "    # convert dataframe to a matrix in order to use numpy shuffle\n",
    "    trans_matrix = df.to_numpy()\n",
    "    \n",
    "    # shuffle and split the data\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(trans_matrix)\n",
    "    \n",
    "    # define the training cut off from the number of rows\n",
    "    nTrain = int(trans_matrix.shape[0] * train_frac)\n",
    "    nFeatures = trans_matrix.shape[1]-1\n",
    "    \n",
    "    # the features are all columns except the first one\n",
    "    train_features = trans_matrix[:nTrain, 1: ]\n",
    "    train_labels = trans_matrix[:nTrain, :1 ]\n",
    "    \n",
    "    test_features = trans_matrix[nTrain: , 1: ]\n",
    "    test_labels = trans_matrix[nTrain: , :1 ]\n",
    "    \n",
    "    return (train_features, train_labels[: , 0]), (test_features, test_labels[: ,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train/test data\n",
    "(train_features, train_labels), (test_features, test_labels) = train_test_split(pca_bc_df, train_frac=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create csv files for use with modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "# We use pandas to save our train and test data to csv files. Note that we make sure not to include header\n",
    "# information or an index \n",
    "\n",
    "pd.concat([pd.DataFrame(train_labels), pd.DataFrame(train_features)], axis=1).to_csv(os.path.join(data_dir, 'nntrain.csv'), header=False, index=False)\n",
    "pd.concat([pd.DataFrame(test_labels), pd.DataFrame(test_features)], axis=1).to_csv(os.path.join(data_dir, 'nntest.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the s3 location prefix\n",
    "prefix = 'nn'\n",
    "\n",
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'nntest.csv'), key_prefix=prefix)\n",
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'nntrain.csv'), key_prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-396358375665/nn/nntest.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-396358375665/nn/nntrain.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-396358375665/nn\n"
     ]
    }
   ],
   "source": [
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial check for epoch overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Define a neural network that performs binary classification.\n",
    "    The network should accept your number of features as input, and produce \n",
    "    a single sigmoid value, that can be rounded to a label: 0 or 1, as output.\n",
    "    \n",
    "    Notes on training:\n",
    "    To train a binary classifier in PyTorch, use BCELoss.\n",
    "    BCELoss is binary cross entropy loss, documentation: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss\n",
    "    \"\"\"\n",
    "\n",
    "    ## Define the init function, the input params are required (for loading code in train.py to work)\n",
    "    def __init__(self, input_features, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up linear layers.\n",
    "        Use the input parameters to help define the layers of your model.\n",
    "        :param input_features: the number of input features in your training/test data\n",
    "        :param hidden_dim: helps define the number of nodes in the hidden layer(s)\n",
    "        :param output_dim: the number of outputs you want to produce\n",
    "        \"\"\"\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "\n",
    "        # define any initial layers, here\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.fc1 = nn.Linear(input_features, hidden_dim)\n",
    "        # apply dropout\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Define activations  \n",
    "        self.a1 = nn.ReLU()\n",
    "        self.a2 = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    ## Define the feed forward behavior of the network\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on input features, x.\n",
    "        :param x: A batch of input features of size (batch_size, input_features)\n",
    "        :return: A single, sigmoid-activated value as output\n",
    "        \"\"\"\n",
    "        \n",
    "        # define the feedforward behavior\n",
    "        x = self.fc1(x)\n",
    "        x = self.a1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.a2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.from_numpy(train_labels).float().squeeze()\n",
    "train_x = torch.from_numpy(train_features).float()\n",
    "\n",
    "train_ds = torch.utils.data.TensorDataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = torch.from_numpy(test_labels).float().squeeze()\n",
    "test_x = torch.from_numpy(test_features).float()\n",
    "\n",
    "test_ds = torch.utils.data.TensorDataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([43])) that is different to the input size (torch.Size([43, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100..  Training Loss: 0.662..  Test Loss: 0.596.. \n",
      "Epoch: 2/100..  Training Loss: 0.581..  Test Loss: 0.524.. \n",
      "Epoch: 3/100..  Training Loss: 0.529..  Test Loss: 0.464.. \n",
      "Epoch: 4/100..  Training Loss: 0.467..  Test Loss: 0.408.. \n",
      "Epoch: 5/100..  Training Loss: 0.409..  Test Loss: 0.358.. \n",
      "Epoch: 6/100..  Training Loss: 0.379..  Test Loss: 0.317.. \n",
      "Epoch: 7/100..  Training Loss: 0.334..  Test Loss: 0.284.. \n",
      "Epoch: 8/100..  Training Loss: 0.310..  Test Loss: 0.251.. \n",
      "Epoch: 9/100..  Training Loss: 0.274..  Test Loss: 0.220.. \n",
      "Epoch: 10/100..  Training Loss: 0.246..  Test Loss: 0.198.. \n",
      "Epoch: 11/100..  Training Loss: 0.226..  Test Loss: 0.176.. \n",
      "Epoch: 12/100..  Training Loss: 0.205..  Test Loss: 0.159.. \n",
      "Epoch: 13/100..  Training Loss: 0.197..  Test Loss: 0.143.. \n",
      "Epoch: 14/100..  Training Loss: 0.166..  Test Loss: 0.134.. \n",
      "Epoch: 15/100..  Training Loss: 0.162..  Test Loss: 0.123.. \n",
      "Epoch: 16/100..  Training Loss: 0.152..  Test Loss: 0.117.. \n",
      "Epoch: 17/100..  Training Loss: 0.146..  Test Loss: 0.117.. \n",
      "Epoch: 18/100..  Training Loss: 0.141..  Test Loss: 0.102.. \n",
      "Epoch: 19/100..  Training Loss: 0.139..  Test Loss: 0.096.. \n",
      "Epoch: 20/100..  Training Loss: 0.124..  Test Loss: 0.091.. \n",
      "Epoch: 21/100..  Training Loss: 0.118..  Test Loss: 0.086.. \n",
      "Epoch: 22/100..  Training Loss: 0.113..  Test Loss: 0.095.. \n",
      "Epoch: 23/100..  Training Loss: 0.109..  Test Loss: 0.082.. \n",
      "Epoch: 24/100..  Training Loss: 0.135..  Test Loss: 0.079.. \n",
      "Epoch: 25/100..  Training Loss: 0.088..  Test Loss: 0.088.. \n",
      "Epoch: 26/100..  Training Loss: 0.115..  Test Loss: 0.086.. \n",
      "Epoch: 27/100..  Training Loss: 0.117..  Test Loss: 0.074.. \n",
      "Epoch: 28/100..  Training Loss: 0.085..  Test Loss: 0.074.. \n",
      "Epoch: 29/100..  Training Loss: 0.088..  Test Loss: 0.081.. \n",
      "Epoch: 30/100..  Training Loss: 0.085..  Test Loss: 0.069.. \n",
      "Epoch: 31/100..  Training Loss: 0.075..  Test Loss: 0.072.. \n",
      "Epoch: 32/100..  Training Loss: 0.084..  Test Loss: 0.067.. \n",
      "Epoch: 33/100..  Training Loss: 0.102..  Test Loss: 0.068.. \n",
      "Epoch: 34/100..  Training Loss: 0.092..  Test Loss: 0.064.. \n",
      "Epoch: 35/100..  Training Loss: 0.074..  Test Loss: 0.065.. \n",
      "Epoch: 36/100..  Training Loss: 0.076..  Test Loss: 0.066.. \n",
      "Epoch: 37/100..  Training Loss: 0.097..  Test Loss: 0.065.. \n",
      "Epoch: 38/100..  Training Loss: 0.071..  Test Loss: 0.076.. \n",
      "Epoch: 39/100..  Training Loss: 0.076..  Test Loss: 0.078.. \n",
      "Epoch: 40/100..  Training Loss: 0.062..  Test Loss: 0.062.. \n",
      "Epoch: 41/100..  Training Loss: 0.067..  Test Loss: 0.061.. \n",
      "Epoch: 42/100..  Training Loss: 0.073..  Test Loss: 0.065.. \n",
      "Epoch: 43/100..  Training Loss: 0.060..  Test Loss: 0.063.. \n",
      "Epoch: 44/100..  Training Loss: 0.077..  Test Loss: 0.065.. \n",
      "Epoch: 45/100..  Training Loss: 0.086..  Test Loss: 0.061.. \n",
      "Epoch: 46/100..  Training Loss: 0.065..  Test Loss: 0.074.. \n",
      "Epoch: 47/100..  Training Loss: 0.063..  Test Loss: 0.077.. \n",
      "Epoch: 48/100..  Training Loss: 0.063..  Test Loss: 0.060.. \n",
      "Epoch: 49/100..  Training Loss: 0.063..  Test Loss: 0.059.. \n",
      "Epoch: 50/100..  Training Loss: 0.079..  Test Loss: 0.062.. \n",
      "Epoch: 51/100..  Training Loss: 0.050..  Test Loss: 0.064.. \n",
      "Epoch: 52/100..  Training Loss: 0.061..  Test Loss: 0.061.. \n",
      "Epoch: 53/100..  Training Loss: 0.050..  Test Loss: 0.079.. \n",
      "Epoch: 54/100..  Training Loss: 0.062..  Test Loss: 0.059.. \n",
      "Epoch: 55/100..  Training Loss: 0.054..  Test Loss: 0.077.. \n",
      "Epoch: 56/100..  Training Loss: 0.053..  Test Loss: 0.061.. \n",
      "Epoch: 57/100..  Training Loss: 0.055..  Test Loss: 0.078.. \n",
      "Epoch: 58/100..  Training Loss: 0.062..  Test Loss: 0.063.. \n",
      "Epoch: 59/100..  Training Loss: 0.064..  Test Loss: 0.063.. \n",
      "Epoch: 60/100..  Training Loss: 0.048..  Test Loss: 0.076.. \n",
      "Epoch: 61/100..  Training Loss: 0.082..  Test Loss: 0.078.. \n",
      "Epoch: 62/100..  Training Loss: 0.061..  Test Loss: 0.060.. \n",
      "Epoch: 63/100..  Training Loss: 0.054..  Test Loss: 0.081.. \n",
      "Epoch: 64/100..  Training Loss: 0.042..  Test Loss: 0.059.. \n",
      "Epoch: 65/100..  Training Loss: 0.055..  Test Loss: 0.081.. \n",
      "Epoch: 66/100..  Training Loss: 0.049..  Test Loss: 0.060.. \n",
      "Epoch: 67/100..  Training Loss: 0.050..  Test Loss: 0.078.. \n",
      "Epoch: 68/100..  Training Loss: 0.051..  Test Loss: 0.064.. \n",
      "Epoch: 69/100..  Training Loss: 0.054..  Test Loss: 0.061.. \n",
      "Epoch: 70/100..  Training Loss: 0.045..  Test Loss: 0.063.. \n",
      "Epoch: 71/100..  Training Loss: 0.043..  Test Loss: 0.065.. \n",
      "Epoch: 72/100..  Training Loss: 0.047..  Test Loss: 0.083.. \n",
      "Epoch: 73/100..  Training Loss: 0.047..  Test Loss: 0.081.. \n",
      "Epoch: 74/100..  Training Loss: 0.043..  Test Loss: 0.079.. \n",
      "Epoch: 75/100..  Training Loss: 0.047..  Test Loss: 0.066.. \n",
      "Epoch: 76/100..  Training Loss: 0.047..  Test Loss: 0.062.. \n",
      "Epoch: 77/100..  Training Loss: 0.046..  Test Loss: 0.062.. \n",
      "Epoch: 78/100..  Training Loss: 0.075..  Test Loss: 0.061.. \n",
      "Epoch: 79/100..  Training Loss: 0.074..  Test Loss: 0.062.. \n",
      "Epoch: 80/100..  Training Loss: 0.046..  Test Loss: 0.064.. \n",
      "Epoch: 81/100..  Training Loss: 0.053..  Test Loss: 0.061.. \n",
      "Epoch: 82/100..  Training Loss: 0.056..  Test Loss: 0.062.. \n",
      "Epoch: 83/100..  Training Loss: 0.053..  Test Loss: 0.060.. \n",
      "Epoch: 84/100..  Training Loss: 0.046..  Test Loss: 0.060.. \n",
      "Epoch: 85/100..  Training Loss: 0.057..  Test Loss: 0.079.. \n",
      "Epoch: 86/100..  Training Loss: 0.041..  Test Loss: 0.061.. \n",
      "Epoch: 87/100..  Training Loss: 0.046..  Test Loss: 0.061.. \n",
      "Epoch: 88/100..  Training Loss: 0.068..  Test Loss: 0.061.. \n",
      "Epoch: 89/100..  Training Loss: 0.051..  Test Loss: 0.065.. \n",
      "Epoch: 90/100..  Training Loss: 0.055..  Test Loss: 0.083.. \n",
      "Epoch: 91/100..  Training Loss: 0.046..  Test Loss: 0.084.. \n",
      "Epoch: 92/100..  Training Loss: 0.042..  Test Loss: 0.066.. \n",
      "Epoch: 93/100..  Training Loss: 0.050..  Test Loss: 0.085.. \n",
      "Epoch: 94/100..  Training Loss: 0.049..  Test Loss: 0.064.. \n",
      "Epoch: 95/100..  Training Loss: 0.047..  Test Loss: 0.086.. \n",
      "Epoch: 96/100..  Training Loss: 0.051..  Test Loss: 0.068.. \n",
      "Epoch: 97/100..  Training Loss: 0.043..  Test Loss: 0.067.. \n",
      "Epoch: 98/100..  Training Loss: 0.049..  Test Loss: 0.065.. \n",
      "Epoch: 99/100..  Training Loss: 0.045..  Test Loss: 0.066.. \n",
      "Epoch: 100/100..  Training Loss: 0.046..  Test Loss: 0.086.. \n"
     ]
    }
   ],
   "source": [
    "model = BinaryClassifier(input_features = 10, hidden_dim = 15, output_dim = 1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    train_loss = 0\n",
    "    for batch in trainloader:\n",
    "        # get data\n",
    "        batch_x, batch_y = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get predictions from model\n",
    "        y_pred = model(batch_x)\n",
    "            \n",
    "        # perform backprop\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        train_loss += loss.data.item()\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for tbatch in testloader:\n",
    "                model.eval()\n",
    "                tbatch_x, tbatch_y = tbatch\n",
    "                ty_pred = model(tbatch_x)\n",
    "                test_loss += criterion(ty_pred, tbatch_y)\n",
    "        \n",
    "    model.train()\n",
    "        \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "            \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
    "            \"Test Loss: {:.3f}.. \".format(test_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd86cc54a20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Validation loss levels off around 50 epochs - so set this to avoid overfitting by the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify an output path\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(# sagemaker details\n",
    "                    sagemaker_session = sagemaker_session,\n",
    "                    role = role,\n",
    "                    output_path = output_path,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "    \n",
    "                    # model source details\n",
    "                    entry_point = 'train.py', \n",
    "                    framework_version='1.0', \n",
    "                    source_dir='nnSource', \n",
    "                    hyperparameters={'input_features':10, # number of variables\n",
    "                                    'hidden_dim':15,\n",
    "                                    'output_dim':1,\n",
    "                                    'batch-size': 64,\n",
    "                                    'lr': 0.003,\n",
    "                                    'epochs': 50\n",
    "                                    }\n",
    "                    \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-11 18:04:31 Starting - Starting the training job...\n",
      "2020-10-11 18:04:33 Starting - Launching requested ML instances......\n",
      "2020-10-11 18:05:33 Starting - Preparing the instances for training...\n",
      "2020-10-11 18:06:31 Downloading - Downloading input data...\n",
      "2020-10-11 18:06:57 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-10-11 18:06:59,287 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-10-11 18:06:59,290 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-10-11 18:06:59,303 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:00,755 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:01,193 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:01,193 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:01,193 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:01,193 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t57yh6kb/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:03,246 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:03,259 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"hidden_dim\": 15,\n",
      "        \"lr\": 0.003,\n",
      "        \"input_features\": 10,\n",
      "        \"epochs\": 50,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-10-11-18-04-31-673\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-396358375665/sagemaker-pytorch-2020-10-11-18-04-31-673/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":50,\"hidden_dim\":15,\"input_features\":10,\"lr\":0.003,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-396358375665/sagemaker-pytorch-2020-10-11-18-04-31-673/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":50,\"hidden_dim\":15,\"input_features\":10,\"lr\":0.003,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2020-10-11-18-04-31-673\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-396358375665/sagemaker-pytorch-2020-10-11-18-04-31-673/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"50\",\"--hidden_dim\",\"15\",\"--input_features\",\"10\",\"--lr\",\"0.003\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=15\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.003\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=10\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --batch-size 64 --epochs 50 --hidden_dim 15 --input_features 10 --lr 0.003 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mGet test data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Training Loss: 0.7038511804171971\u001b[0m\n",
      "\u001b[34mEpoch: 2, Training Loss: 0.6350504074777875\u001b[0m\n",
      "\u001b[34mEpoch: 3, Training Loss: 0.5706402574266706\u001b[0m\n",
      "\u001b[34mEpoch: 4, Training Loss: 0.5142622249467033\u001b[0m\n",
      "\u001b[34mEpoch: 5, Training Loss: 0.4707763024738857\u001b[0m\n",
      "\u001b[34mEpoch: 6, Training Loss: 0.419934413262776\u001b[0m\n",
      "\u001b[34mEpoch: 7, Training Loss: 0.38431717668260845\u001b[0m\n",
      "\u001b[34mEpoch: 8, Training Loss: 0.3409982791968754\u001b[0m\n",
      "\u001b[34mEpoch: 9, Training Loss: 0.31505433150700163\u001b[0m\n",
      "\u001b[34mEpoch: 10, Training Loss: 0.28774859649794443\u001b[0m\n",
      "\u001b[34mEpoch: 11, Training Loss: 0.2619594505855015\u001b[0m\n",
      "\u001b[34mEpoch: 12, Training Loss: 0.23283634228365763\u001b[0m\n",
      "\u001b[34mEpoch: 13, Training Loss: 0.2086753568478993\u001b[0m\n",
      "\u001b[34mEpoch: 14, Training Loss: 0.18956959886210306\u001b[0m\n",
      "\u001b[34mEpoch: 15, Training Loss: 0.1806792446545192\u001b[0m\n",
      "\u001b[34mEpoch: 16, Training Loss: 0.1584376341530255\u001b[0m\n",
      "\u001b[34mEpoch: 17, Training Loss: 0.1475027267421995\u001b[0m\n",
      "\u001b[34mEpoch: 18, Training Loss: 0.13784985776458467\u001b[0m\n",
      "\u001b[34mEpoch: 19, Training Loss: 0.13063997881753103\u001b[0m\n",
      "\u001b[34mEpoch: 20, Training Loss: 0.1267541583095278\u001b[0m\n",
      "\u001b[34mEpoch: 21, Training Loss: 0.11752106142895562\u001b[0m\n",
      "\u001b[34mEpoch: 22, Training Loss: 0.10931478547198432\u001b[0m\n",
      "\u001b[34mEpoch: 23, Training Loss: 0.11323913080351693\u001b[0m\n",
      "\u001b[34mEpoch: 24, Training Loss: 0.10171888555799212\u001b[0m\n",
      "\u001b[34mEpoch: 25, Training Loss: 0.09103116126997131\u001b[0m\n",
      "\u001b[34mEpoch: 26, Training Loss: 0.09125402782644544\u001b[0m\n",
      "\u001b[34mEpoch: 27, Training Loss: 0.09973666178328651\u001b[0m\n",
      "\u001b[34mEpoch: 28, Training Loss: 0.0911628742303167\u001b[0m\n",
      "\u001b[34mEpoch: 29, Training Loss: 0.08708389369504792\u001b[0m\n",
      "\u001b[34mEpoch: 30, Training Loss: 0.08276349891509328\u001b[0m\n",
      "\u001b[34mEpoch: 31, Training Loss: 0.07837972257818494\u001b[0m\n",
      "\u001b[34mEpoch: 32, Training Loss: 0.08581292895334107\u001b[0m\n",
      "\u001b[34mEpoch: 33, Training Loss: 0.08006460006747927\u001b[0m\n",
      "\u001b[34mEpoch: 34, Training Loss: 0.07691336928733758\u001b[0m\n",
      "\u001b[34mEpoch: 35, Training Loss: 0.06781062696661268\u001b[0m\n",
      "\u001b[34mEpoch: 36, Training Loss: 0.08399825117417745\u001b[0m\n",
      "\u001b[34mEpoch: 37, Training Loss: 0.06571567271436964\u001b[0m\n",
      "\u001b[34mEpoch: 38, Training Loss: 0.07466731992151056\u001b[0m\n",
      "\u001b[34mEpoch: 39, Training Loss: 0.08116908105356353\u001b[0m\n",
      "\u001b[34mEpoch: 40, Training Loss: 0.06907345434384686\u001b[0m\n",
      "\u001b[34mEpoch: 41, Training Loss: 0.06874644064477511\u001b[0m\n",
      "\u001b[34mEpoch: 42, Training Loss: 0.0637271696967738\u001b[0m\n",
      "\u001b[34mEpoch: 43, Training Loss: 0.06084186903067997\u001b[0m\n",
      "\u001b[34mEpoch: 44, Training Loss: 0.06153202562459877\u001b[0m\n",
      "\u001b[34mEpoch: 45, Training Loss: 0.062145277591688294\u001b[0m\n",
      "\u001b[34mEpoch: 46, Training Loss: 0.06366714462637901\u001b[0m\n",
      "\u001b[34mEpoch: 47, Training Loss: 0.06076774666351931\u001b[0m\n",
      "\u001b[34mEpoch: 48, Training Loss: 0.05588082317262888\u001b[0m\n",
      "\u001b[34mEpoch: 49, Training Loss: 0.06269324836986405\u001b[0m\n",
      "\u001b[34mEpoch: 50, Training Loss: 0.06807495547192437\u001b[0m\n",
      "\u001b[34m2020-10-11 18:07:05,512 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-10-11 18:07:15 Uploading - Uploading generated training model\n",
      "2020-10-11 18:07:15 Completed - Training job completed\n",
      "Training seconds: 44\n",
      "Billable seconds: 44\n",
      "CPU times: user 516 ms, sys: 20.3 ms, total: 536 ms\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 0 ns, total: 16 ms\n",
      "Wall time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "model = PyTorchModel(# sagemaker details\n",
    "                    role = role,\n",
    "                    # model details\n",
    "                    framework_version='1.0',\n",
    "                    model_data = estimator.model_data,\n",
    "                    source_dir = 'nnSource',\n",
    "                    entry_point = 'predict.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 401 ms, sys: 34.3 ms, total: 435 ms\n",
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test data, assuming it is stored locally\n",
    "train_data = pd.read_csv(os.path.join(data_dir, \"nntrain.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "train_y = train_data.iloc[:,0]\n",
    "train_x = train_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"nntest.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the training data as a robustness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_preds = np.squeeze(np.round(predictor.predict(train_x)))\n",
    "train_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a variety of model metrics\n",
    "def evaluate(test_preds, test_labels,  verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint outcomes.  \n",
    "    Return binary classification metrics.\n",
    "    :param test_preds: A prediction endpoint output as a dataframe\n",
    "    :param test_labels: Class labels for test data as a dataframe\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics Neural Network Model.\n",
      "\n",
      "prediction (col)  0.0  1.0\n",
      "actual (row)              \n",
      "0.0               247    2\n",
      "1.0                 4  145\n",
      "\n",
      "Recall:     0.973\n",
      "Precision:  0.986\n",
      "Accuracy:   0.985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Metrics Neural Network Model.\\n')\n",
    "\n",
    "# get metrics for neural net predictor\n",
    "metrics = evaluate(train_y_preds, \n",
    "                   train_y, \n",
    "                   verbose=True) # verbose means we'll print out the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the test data for model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_preds = np.squeeze(np.round(predictor.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics Neural Network Model.\n",
      "\n",
      "prediction (col)  0.0  1.0\n",
      "actual (row)              \n",
      "0.0               108    0\n",
      "1.0                 2   61\n",
      "\n",
      "Recall:     0.968\n",
      "Precision:  1.000\n",
      "Accuracy:   0.988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics Neural Network Model.\\n')\n",
    "\n",
    "# get metrics for neural net predictor\n",
    "metrics = evaluate(test_y_preds, \n",
    "                   test_y, \n",
    "                   verbose=True) # verbose means we'll print out the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes a precictor.endpoint\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-10-11-18-14-37-985\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
